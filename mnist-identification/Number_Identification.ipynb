{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Number Identification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willystw/fastai-learning/blob/modify-output/mnist-identification/Number_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "e77_7tlwNPFO"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "The application uses fastai & pytorch library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "UCwd3W_hNPFQ"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "3hktkGrbNPFR"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "Q2ZyRwIRNPFS"
      },
      "source": [
        "### Download Raw Data\n",
        "\n",
        "Raw data used here is from fastai course, because the data is in image format, and the image size is identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "i3Fs1IkGNPFS",
        "outputId": "828519aa-7726-4b98-985b-2e036563e8d2"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "gCRzFDlLNPFT"
      },
      "source": [
        "Path.BASE_PATH = path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUgLwQTUNPFT",
        "outputId": "6e15feb3-3970-4d14-af5d-dcb819e23b7d"
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('training'),Path('testing')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4zgzTuGNPFV",
        "outputId": "373d8508-c6f4-42fd-b4b1-e521121c71be"
      },
      "source": [
        "(path/'training').ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('training/7'),Path('training/8'),Path('training/5'),Path('training/4'),Path('training/6'),Path('training/3'),Path('training/2'),Path('training/9'),Path('training/1'),Path('training/0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVWtB9W1NPFV",
        "outputId": "91315e6e-de03-41b5-e405-da74e5fa2753"
      },
      "source": [
        "(path/'testing').ls()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('testing/7'),Path('testing/8'),Path('testing/5'),Path('testing/4'),Path('testing/6'),Path('testing/3'),Path('testing/2'),Path('testing/9'),Path('testing/1'),Path('testing/0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "O2Ts27J0NPFW"
      },
      "source": [
        "fours = (path/'training/4').ls().sorted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSHRSUKLNPFX",
        "outputId": "6dcd7fa6-3d9f-4f6a-890e-7992726d7cd6"
      },
      "source": [
        "len(fours)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "aLL9BU1BNPFX",
        "outputId": "2983eace-d132-454e-980a-b42dc692581d"
      },
      "source": [
        "Image.open(fours[542])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7ElEQVR4nM2PPUvDUBSGnyuChG4F0WQoNNBNpwwOrqV/QBz6FzoXZ/9DF0chdCkijsHBzUk6CR1aECedmkKhxOX0OKT56G0rdPOFw305z/m68O9Ve3v27NxF20lNT+TJYtdTCVP3KhJZMFpK7ALwVcDD1WsMP98At6fQt6CqzgCoK8OHVfKgmPyRmVGyCQMAv1k6JN+JATgauKSuDGP0OHyc3TVQ1PoJwUJElmncZ8ls57Bjl1OaT7PrnY0/X6o3a1fmck4q0BIR+yCAJAH8LV25zhciWcHG+Pe5MZe7IKp6tRP+qVAm7n4d++oX+UBJkFxNToQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F941550DE90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9twF--yNPFY"
      },
      "source": [
        "## Init Variables\n",
        "\n",
        "Store images data to a variable, then convert it to a tensor array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "mUiek4V2NPFY"
      },
      "source": [
        "zeros = (path/'training/0').ls().sorted()\n",
        "ones = (path/'training/1').ls().sorted()\n",
        "twos = (path/'training/2').ls().sorted()\n",
        "threes = (path/'training/3').ls().sorted()\n",
        "fours = (path/'training/4').ls().sorted()\n",
        "fives = (path/'training/5').ls().sorted()\n",
        "sixes = (path/'training/6').ls().sorted()\n",
        "sevens = (path/'training/7').ls().sorted()\n",
        "eights = (path/'training/8').ls().sorted()\n",
        "nines = (path/'training/9').ls().sorted()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "e55fBR28NPFZ"
      },
      "source": [
        "zero_tensor = [tensor(Image.open(o)) for o in zeros]\n",
        "one_tensor = [tensor(Image.open(o)) for o in ones]\n",
        "two_tensor = [tensor(Image.open(o)) for o in twos]\n",
        "three_tensor = [tensor(Image.open(o)) for o in threes]\n",
        "four_tensor = [tensor(Image.open(o)) for o in fours]\n",
        "five_tensor = [tensor(Image.open(o)) for o in fives]\n",
        "six_tensor = [tensor(Image.open(o)) for o in sixes]\n",
        "seven_tensor = [tensor(Image.open(o)) for o in sevens]\n",
        "eight_tensor = [tensor(Image.open(o)) for o in eights]\n",
        "nine_tensor = [tensor(Image.open(o)) for o in nines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CW5oygS0Zkf"
      },
      "source": [
        "zero_stack = torch.stack(zero_tensor).float()/255.0\n",
        "one_stack = torch.stack(one_tensor).float()/255.0\n",
        "two_stack = torch.stack(two_tensor).float()/255.0\n",
        "three_stack = torch.stack(three_tensor).float()/255.0\n",
        "four_stack = torch.stack(four_tensor).float()/255.0\n",
        "five_stack = torch.stack(five_tensor).float()/255.0\n",
        "six_stack = torch.stack(six_tensor).float()/255.0\n",
        "seven_stack = torch.stack(seven_tensor).float()/255.0\n",
        "eight_stack = torch.stack(eight_tensor).float()/255.0\n",
        "nine_stack = torch.stack(nine_tensor).float()/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1VDufAq0c37"
      },
      "source": [
        "zero_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/0').ls().sorted()]).float()/255.0\n",
        "one_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/1').ls().sorted()]).float()/255.0\n",
        "two_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/2').ls().sorted()]).float()/255.0\n",
        "three_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/3').ls().sorted()]).float()/255.0\n",
        "four_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/4').ls().sorted()]).float()/255.0\n",
        "five_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/5').ls().sorted()]).float()/255.0\n",
        "six_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/6').ls().sorted()]).float()/255.0\n",
        "seven_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/7').ls().sorted()]).float()/255.0\n",
        "eight_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/8').ls().sorted()]).float()/255.0\n",
        "nine_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/9').ls().sorted()]).float()/255.0\n",
        "\n",
        "t_tensors = [zero_t_tensor, one_t_tensor, two_t_tensor, three_t_tensor, four_t_tensor, \n",
        "            five_t_tensor, six_t_tensor, seven_t_tensor, eight_t_tensor, nine_t_tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRiR1As7NPFZ"
      },
      "source": [
        "## Using Pixel Similarity Method\n",
        "\n",
        "In this method, get average pixel value of a number. Then, calculate similarity with each number to determine which number is closest to prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "BWS9uLMnNPFa"
      },
      "source": [
        "mean0 = zero_stack.mean(0)\n",
        "mean1 = one_stack.mean(0)\n",
        "mean2 = two_stack.mean(0)\n",
        "mean3 = three_stack.mean(0)\n",
        "mean4 = four_stack.mean(0)\n",
        "mean5 = five_stack.mean(0)\n",
        "mean6 = six_stack.mean(0)\n",
        "mean7 = seven_stack.mean(0)\n",
        "mean8 = eight_stack.mean(0)\n",
        "mean9 = nine_stack.mean(0)\n",
        "\n",
        "means = [zero_stack.mean(0), one_stack.mean(0), two_stack.mean(0), three_stack.mean(0), four_stack.mean(0), \n",
        "         five_stack.mean(0), six_stack.mean(0), seven_stack.mean(0), eight_stack.mean(0), nine_stack.mean(0)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hZBLmBgNPFa"
      },
      "source": [
        "Define distance function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "SFxh9VxfNPFa"
      },
      "source": [
        "def distance(a,b) : return (a-b).abs().mean((-1,-2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE1HZLD_NPFa"
      },
      "source": [
        "Use test data to get the function accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "E537k8qCNPFb"
      },
      "source": [
        "def get_accuracy(tensor_input, predicted_num):\n",
        "    #init with true elements\n",
        "    result = torch.ones(len(tensor_input), dtype=torch.bool)\n",
        "    #get distance between input and predicted number's mean\n",
        "    base = distance(tensor_input, means[predicted_num])\n",
        "    #iterate 9 times to compare distance between input tensor and other available numbers.\n",
        "    #skip if i is predicted_num\n",
        "    #use logical and to accummulate the result\n",
        "    for i in range(0,10):\n",
        "        if i == predicted_num:\n",
        "            continue\n",
        "        d = distance(tensor_input, means[i])\n",
        "        acc = base < d\n",
        "        result = torch.logical_and(result, acc)\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_accuracy_list(predicted_num):\n",
        "    \"\"\"Combine multiple get_accuracy functions into one function.\n",
        "    Take data from t_tensors and iterate it.\n",
        "    If the index of iteration is the same as predicted_num, use get_accuracy.\n",
        "    Otherwise, use 1-get_accuracy to predict the chance of not predicted_num.\n",
        "    Index 0 of the result is the correctness of test data compared with its predicted_num \n",
        "    \"\"\"\n",
        "    result = [get_accuracy(t_tensors[predicted_num], predicted_num).float().mean()]\n",
        "    for i in range(0, 10):\n",
        "        if i == predicted_num:\n",
        "            continue\n",
        "        pred = get_accuracy(t_tensors[i], predicted_num).float().mean()\n",
        "        result.append((1 - pred))    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fllP-W9CNPFb",
        "outputId": "76558dc8-b994-4ef5-c3b1-605a2067f68e"
      },
      "source": [
        "for i in range(0,10):\n",
        "    r = get_accuracy_list(i)\n",
        "    print(f\"Accuracy of number {i} is {r} with mean {torch.mean(torch.stack(r))}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of number 0 is [tensor(0.8153), tensor(1.), tensor(0.9835), tensor(0.9990), tensor(1.), tensor(0.9933), tensor(0.9906), tensor(0.9990), tensor(0.9887), tensor(0.9911)] with mean 0.9760535955429077\n",
            "Accuracy of number 1 is [tensor(0.9982), tensor(0.9449), tensor(0.5678), tensor(0.6832), tensor(0.8320), tensor(0.6357), tensor(0.8455), tensor(0.8064), tensor(0.6191), tensor(0.8840)] with mean 0.781683087348938\n",
            "Accuracy of number 2 is [tensor(0.4234), tensor(1.), tensor(1.), tensor(0.9950), tensor(1.), tensor(1.), tensor(0.9958), tensor(0.9981), tensor(1.), tensor(0.9990)] with mean 0.941138744354248\n",
            "Accuracy of number 3 is [tensor(0.6089), tensor(0.9898), tensor(0.9991), tensor(0.9767), tensor(1.), tensor(0.8374), tensor(1.), tensor(1.), tensor(0.9476), tensor(0.9931)] with mean 0.9352714419364929\n",
            "Accuracy of number 4 is [tensor(0.6680), tensor(0.9969), tensor(1.), tensor(0.9767), tensor(0.9990), tensor(0.9787), tensor(0.9614), tensor(0.9932), tensor(0.9908), tensor(0.9594)] with mean 0.9524110555648804\n",
            "Accuracy of number 5 is [tensor(0.3262), tensor(0.9735), tensor(1.), tensor(1.), tensor(0.9950), tensor(1.), tensor(0.9948), tensor(1.), tensor(0.9928), tensor(0.9990)] with mean 0.9281355142593384\n",
            "Accuracy of number 6 is [tensor(0.7871), tensor(0.9500), tensor(0.9991), tensor(0.9777), tensor(0.9970), tensor(0.9888), tensor(0.9765), tensor(1.), tensor(0.9887), tensor(0.9960)] with mean 0.9660916328430176\n",
            "Accuracy of number 7 is [tensor(0.7646), tensor(0.9908), tensor(1.), tensor(0.9767), tensor(0.9851), tensor(0.9990), tensor(0.9742), tensor(1.), tensor(0.9846), tensor(0.9594)] with mean 0.9634462594985962\n",
            "Accuracy of number 8 is [tensor(0.4425), tensor(0.9898), tensor(1.), tensor(0.9748), tensor(0.9822), tensor(1.), tensor(0.9966), tensor(1.), tensor(0.9981), tensor(0.9950)] with mean 0.9379020929336548\n",
            "Accuracy of number 9 is [tensor(0.7760), tensor(0.9796), tensor(1.), tensor(0.9893), tensor(0.9733), tensor(0.8483), tensor(0.9339), tensor(0.9990), tensor(0.9698), tensor(0.9302)] with mean 0.939932644367218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnahVl0rNPFc"
      },
      "source": [
        "## Conclusion of Using Pixel Similarity Method\n",
        "\n",
        "Most of the test result performs well, with mean > 0.90, although there are some concerns. Some test data does not perform well if tested with the correct number. For example, test 5 only has 0.2276 in confidence that the number tested is 5. For further improvement, test with other methods (e.g Stochastic Gradient Descent /SGD) to get better accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMRpanjnPtB6"
      },
      "source": [
        "## Using Stochastic Gradient Descent\n",
        "\n",
        "Stochastic Gradient Descent (SGD) is a method to optimize objective function with suitable smoothness properties iteratively. The difference between SGD and gradient descent is that SGD uses mini-batch instead of processing all inputs at once, which makes SGD faster and cost efficient.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD4X_ylbSmFg"
      },
      "source": [
        "There are seven steps when trying to identify number using SGD:\n",
        "\n",
        "1. Initialize weight with random value\n",
        "1. Predict the number\n",
        "1. Calculate the model loss (how far the prediction from actual result)\n",
        "1. Calculate gradient, to measure new weight\n",
        "1. Step(change) all the weight based on calculation\n",
        "1. Go back to step 2, and repeat\n",
        "1. Iterate until you decide to stop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "kp4oZuBUWbxD",
        "outputId": "55821bf6-46e3-473b-dc20-e133dbeaa3a8"
      },
      "source": [
        "gv('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f792f923950>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"597pt\" height=\"78pt\"\n viewBox=\"0.00 0.00 596.69 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-74 592.6863,-74 592.6863,4 -4,4\"/>\n<!-- init -->\n<g id=\"node1\" class=\"node\">\n<title>init</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">init</text>\n</g>\n<!-- predict -->\n<g id=\"node2\" class=\"node\">\n<title>predict</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127.3968\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"127.3968\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n</g>\n<!-- init&#45;&gt;predict -->\n<g id=\"edge1\" class=\"edge\">\n<title>init&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1688,-18C62.3543,-18 71.5827,-18 80.6596,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7795,-21.5001 90.7795,-18 80.7795,-14.5001 80.7795,-21.5001\"/>\n</g>\n<!-- loss -->\n<g id=\"node3\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.7935\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"227.7935\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- predict&#45;&gt;loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>predict&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5191,-28.2011C168.9806,-32.0826 182.1139,-36.5303 193.9014,-40.5222\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.8259,-43.8532 203.4202,-43.7458 195.0713,-37.2231 192.8259,-43.8532\"/>\n</g>\n<!-- gradient -->\n<g id=\"node4\" class=\"node\">\n<title>gradient</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.7399\" cy=\"-52\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"365.7399\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gradient</text>\n</g>\n<!-- loss&#45;&gt;gradient -->\n<g id=\"edge3\" class=\"edge\">\n<title>loss&#45;&gt;gradient</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.0473,-52C272.0415,-52 294.4481,-52 314.6545,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.671,-55.5001 324.671,-52 314.671,-48.5001 314.671,-55.5001\"/>\n</g>\n<!-- step -->\n<g id=\"node5\" class=\"node\">\n<title>step</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"470.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"470.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step</text>\n</g>\n<!-- gradient&#45;&gt;step -->\n<g id=\"edge4\" class=\"edge\">\n<title>gradient&#45;&gt;step</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M398.9456,-41.2422C410.9558,-37.3512 424.5297,-32.9536 436.6132,-29.0388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.9112,-32.2975 446.3457,-25.8857 435.7537,-25.6382 437.9112,-32.2975\"/>\n</g>\n<!-- step&#45;&gt;predict -->\n<g id=\"edge6\" class=\"edge\">\n<title>step&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.4266,-18C384.9297,-18 246.7861,-18 174.0495,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.8098,-14.5001 163.8098,-18 173.8097,-21.5001 173.8098,-14.5001\"/>\n<text text-anchor=\"middle\" x=\"289.7935\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n</g>\n<!-- stop -->\n<g id=\"node6\" class=\"node\">\n<title>stop</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"561.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"561.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n</g>\n<!-- step&#45;&gt;stop -->\n<g id=\"edge5\" class=\"edge\">\n<title>step&#45;&gt;stop</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M497.9893,-18C506.2676,-18 515.508,-18 524.3268,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.4026,-21.5001 534.4025,-18 524.4025,-14.5001 524.4026,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BuIIpr-bnP4"
      },
      "source": [
        "### Mini-Batch\n",
        "To split data into several batches, I use `DataLoader` class to load data, randomize the entry, and split the data into several batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI8MqZz5cWio"
      },
      "source": [
        "train_x = torch.cat([zero_stack, one_stack,  two_stack, three_stack, four_stack, five_stack, six_stack, seven_stack, eight_stack, nine_stack]).view(-1, 28*28)\n",
        "train_y = tensor([0]* len(zeros) + [1]* len(ones) + [2]* len(twos) + [3]* len(threes) + [4]* len(fours) + [5]* len(fives) + \n",
        "                 [6]* len(sixes) + [7]* len(sevens) + [8]* len(eights) + [9]* len(nines))\n",
        "train_dl = DataLoader(list(zip(train_x, train_y)), batch_size=256)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcq-Zf_Jd129"
      },
      "source": [
        "validation_x = torch.cat([zero_t_tensor, one_t_tensor, two_t_tensor, three_t_tensor, four_t_tensor, five_t_tensor, \n",
        "                     six_t_tensor, seven_t_tensor, eight_t_tensor, nine_t_tensor]).view(-1, 28*28)\n",
        "validation_y = tensor([0]* len(zero_t_tensor) + [1]* len(one_t_tensor) + [2]* len(two_t_tensor) + [3]* len(three_t_tensor) + [4]* len(four_t_tensor) + [5]* len(five_t_tensor) + \n",
        "                 [6]* len(six_t_tensor) + [7]* len(seven_t_tensor) + [8]* len(eight_t_tensor) + [9]* len(nine_t_tensor))\n",
        "validation_dl = DataLoader(list(zip(validation_x, validation_y)), batch_size=256)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfy5BzPRnnEu"
      },
      "source": [
        "In the code above, I map the X axis with image tensors, and Y axis with numbering label to create training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sg_Evu-vSTA"
      },
      "source": [
        "def train_epoch(model):\n",
        "  result = []\n",
        "  for xb, yb in train_dl:\n",
        "    loss = calculate_gradient(xb, yb, model)\n",
        "    for p in params:\n",
        "      p.data -= p.grad * lr\n",
        "      p.grad.zero_()\n",
        "    result.append(loss.detach())\n",
        "  return torch.stack(result).mean()\n",
        "\n",
        "def calculate_gradient(xb, yb, model, loss_func=F.cross_entropy):\n",
        "  preds = model(xb)\n",
        "  loss = loss_func(preds, yb)\n",
        "  loss.backward()\n",
        "\n",
        "  return loss\n",
        "\n",
        "def train_model(model, epochs):\n",
        "    for i in range(epochs):\n",
        "        loss = train_epoch(model)\n",
        "        accuracy = validate_epoch(model)\n",
        "        print(f\"Loss: {loss}\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        \n",
        "def linear1(xb):\n",
        "    return xb@w + b\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLISkMvOQ8Uy"
      },
      "source": [
        "def validate_epoch(model):\n",
        "  accs = [batch_accuracy(model(xb), yb) for xb, yb in validation_dl]\n",
        "  return round(torch.stack(accs).mean().item(), 4)\n",
        "\n",
        "def batch_accuracy(result, yb):\n",
        "  scores = result.softmax(1)\n",
        "  accuracy = num_correct(scores, yb) / float(yb.size(0))\n",
        "  return accuracy\n",
        "\n",
        "def num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).float().sum()\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH3HckkZIGNG"
      },
      "source": [
        "I define several functions. `train_model` is the main method that will be used to view function loss and mode accuracy. In every epoch, functions `train_epoch` and `validate_epoch` is called sequentially. In `train_epoch`, the function will calculate gradient by using cross entropy.\n",
        "\n",
        "In validation process, `batch_accuracy` will caluclate SoftMax distribution. This distribution determines probability of a numeric image detection result from number 0 to 9. In `num_correct`, the function will get which array index (array index is a representation of number result) has highest probability, and will be compared with actual result to test the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq11AOR9zLbx"
      },
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
        "\n",
        "#Init variables with random values\n",
        "w = init_params((28*28, 10))\n",
        "b = init_params(10)\n",
        "\n",
        "params = w , b\n",
        "lr = 1.\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iblC1XF3JBeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f520c4-a3ec-4899-d79a-c131202c8193"
      },
      "source": [
        "#Print weight and bias before training\n",
        "params"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.4928, -1.4255, -0.2927,  ...,  0.7329, -1.7066, -0.0449],\n",
              "         [-0.2082, -0.8302, -0.0835,  ..., -0.9769,  0.4104, -0.4193],\n",
              "         [-0.0752,  0.1258, -0.2083,  ..., -0.8707,  0.2897, -0.2699],\n",
              "         ...,\n",
              "         [ 0.8049,  0.0775, -0.1371,  ..., -1.2666, -1.1943, -0.5013],\n",
              "         [-0.9817, -0.5424, -1.2354,  ..., -0.2341, -0.3318, -0.5822],\n",
              "         [ 1.5308,  1.8972,  0.7352,  ...,  0.2311, -0.3228,  0.1472]], requires_grad=True),\n",
              " tensor([-2.2794,  0.8107,  0.1559, -0.4761, -0.0702,  3.5993,  0.3713,  4.5749, -1.7764,  0.5655], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrBsW-Q47uU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc2c947-e72e-44b9-c8cc-1a61de7ca28f"
      },
      "source": [
        "validate_epoch(linear1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVb7z0T9ynRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f285919e-8355-40d0-b43e-cb0f66d3c4a8"
      },
      "source": [
        "train_model(linear1, 20)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.19902178645133972\n",
            "Accuracy: 0.5076\n",
            "Loss: 0.19693732261657715\n",
            "Accuracy: 0.5086\n",
            "Loss: 0.19496780633926392\n",
            "Accuracy: 0.5096\n",
            "Loss: 0.19310912489891052\n",
            "Accuracy: 0.5105\n",
            "Loss: 0.1913589984178543\n",
            "Accuracy: 0.5119\n",
            "Loss: 0.18971635401248932\n",
            "Accuracy: 0.5137\n",
            "Loss: 0.18817995488643646\n",
            "Accuracy: 0.5154\n",
            "Loss: 0.18674622476100922\n",
            "Accuracy: 0.5159\n",
            "Loss: 0.1854086071252823\n",
            "Accuracy: 0.5166\n",
            "Loss: 0.1841580867767334\n",
            "Accuracy: 0.5183\n",
            "Loss: 0.18298470973968506\n",
            "Accuracy: 0.5188\n",
            "Loss: 0.18187884986400604\n",
            "Accuracy: 0.5198\n",
            "Loss: 0.18083156645298004\n",
            "Accuracy: 0.5217\n",
            "Loss: 0.1798352301120758\n",
            "Accuracy: 0.5223\n",
            "Loss: 0.1788831502199173\n",
            "Accuracy: 0.5232\n",
            "Loss: 0.17796969413757324\n",
            "Accuracy: 0.5242\n",
            "Loss: 0.17708991467952728\n",
            "Accuracy: 0.5246\n",
            "Loss: 0.17623953521251678\n",
            "Accuracy: 0.5252\n",
            "Loss: 0.17541471123695374\n",
            "Accuracy: 0.5261\n",
            "Loss: 0.17461197078227997\n",
            "Accuracy: 0.5266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT_X-dJAI-T1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947ec435-d81c-481b-d354-e91352612608"
      },
      "source": [
        "# Print weight and bias after training\n",
        "params"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.4928, -1.4255, -0.2927,  ...,  0.7329, -1.7066, -0.0449],\n",
              "         [-0.2082, -0.8302, -0.0835,  ..., -0.9769,  0.4104, -0.4193],\n",
              "         [-0.0752,  0.1258, -0.2083,  ..., -0.8707,  0.2897, -0.2699],\n",
              "         ...,\n",
              "         [ 0.8049,  0.0775, -0.1371,  ..., -1.2666, -1.1943, -0.5013],\n",
              "         [-0.9817, -0.5424, -1.2354,  ..., -0.2341, -0.3318, -0.5822],\n",
              "         [ 1.5308,  1.8972,  0.7352,  ...,  0.2311, -0.3228,  0.1472]], requires_grad=True),\n",
              " tensor([-2.5713,  1.0068,  0.3734, -0.7523, -0.1599,  4.1913,  0.3311,  4.7359, -2.1798,  0.5001], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}