{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Number Identification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willystw/fastai-learning/blob/chg-output/mnist-identification/Number_Identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "e77_7tlwNPFO"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "The application uses fastai & pytorch library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "UCwd3W_hNPFQ"
      },
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "3hktkGrbNPFR"
      },
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "Q2ZyRwIRNPFS"
      },
      "source": [
        "### Download Raw Data\n",
        "\n",
        "Raw data used here is from fastai course, because the data is in image format, and the image size is identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "i3Fs1IkGNPFS",
        "outputId": "d1a6d86c-fed4-4696-91ef-86121a90ab85"
      },
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "gCRzFDlLNPFT"
      },
      "source": [
        "Path.BASE_PATH = path"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUgLwQTUNPFT",
        "outputId": "ab06fa12-687b-4e23-d726-1bef70325297"
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('testing'),Path('training')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4zgzTuGNPFV",
        "outputId": "1e1c981c-b41b-420c-e79b-f58f75cac2a8"
      },
      "source": [
        "(path/'training').ls()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('training/0'),Path('training/3'),Path('training/1'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/9'),Path('training/7'),Path('training/8'),Path('training/2')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVWtB9W1NPFV",
        "outputId": "04cc0d10-e7d4-4f06-d207-0fe1ae3504cb"
      },
      "source": [
        "(path/'testing').ls()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [Path('testing/0'),Path('testing/3'),Path('testing/1'),Path('testing/4'),Path('testing/5'),Path('testing/6'),Path('testing/9'),Path('testing/7'),Path('testing/8'),Path('testing/2')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "O2Ts27J0NPFW"
      },
      "source": [
        "fours = (path/'training/4').ls().sorted()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSHRSUKLNPFX",
        "outputId": "648fa066-1ce1-406d-ea00-c0fad589e64e"
      },
      "source": [
        "len(fours)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "aLL9BU1BNPFX",
        "outputId": "4fbf5774-da1e-4e30-b4dc-884ede1652a8"
      },
      "source": [
        "Image.open(fours[542])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7ElEQVR4nM2PPUvDUBSGnyuChG4F0WQoNNBNpwwOrqV/QBz6FzoXZ/9DF0chdCkijsHBzUk6CR1aECedmkKhxOX0OKT56G0rdPOFw305z/m68O9Ve3v27NxF20lNT+TJYtdTCVP3KhJZMFpK7ALwVcDD1WsMP98At6fQt6CqzgCoK8OHVfKgmPyRmVGyCQMAv1k6JN+JATgauKSuDGP0OHyc3TVQ1PoJwUJElmncZ8ls57Bjl1OaT7PrnY0/X6o3a1fmck4q0BIR+yCAJAH8LV25zhciWcHG+Pe5MZe7IKp6tRP+qVAm7n4d++oX+UBJkFxNToQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F87118DFBD0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9twF--yNPFY"
      },
      "source": [
        "## Init Variables\n",
        "\n",
        "Store images data to a variable, then convert it to a tensor array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "mUiek4V2NPFY"
      },
      "source": [
        "zeros = (path/'training/0').ls().sorted()\n",
        "ones = (path/'training/1').ls().sorted()\n",
        "twos = (path/'training/2').ls().sorted()\n",
        "threes = (path/'training/3').ls().sorted()\n",
        "fours = (path/'training/4').ls().sorted()\n",
        "fives = (path/'training/5').ls().sorted()\n",
        "sixes = (path/'training/6').ls().sorted()\n",
        "sevens = (path/'training/7').ls().sorted()\n",
        "eights = (path/'training/8').ls().sorted()\n",
        "nines = (path/'training/9').ls().sorted()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "gradient": {},
        "id": "e55fBR28NPFZ"
      },
      "source": [
        "zero_tensor = [tensor(Image.open(o)) for o in zeros]\n",
        "one_tensor = [tensor(Image.open(o)) for o in ones]\n",
        "two_tensor = [tensor(Image.open(o)) for o in twos]\n",
        "three_tensor = [tensor(Image.open(o)) for o in threes]\n",
        "four_tensor = [tensor(Image.open(o)) for o in fours]\n",
        "five_tensor = [tensor(Image.open(o)) for o in fives]\n",
        "six_tensor = [tensor(Image.open(o)) for o in sixes]\n",
        "seven_tensor = [tensor(Image.open(o)) for o in sevens]\n",
        "eight_tensor = [tensor(Image.open(o)) for o in eights]\n",
        "nine_tensor = [tensor(Image.open(o)) for o in nines]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CW5oygS0Zkf"
      },
      "source": [
        "zero_stack = torch.stack(zero_tensor).float()/255.0\n",
        "one_stack = torch.stack(one_tensor).float()/255.0\n",
        "two_stack = torch.stack(two_tensor).float()/255.0\n",
        "three_stack = torch.stack(three_tensor).float()/255.0\n",
        "four_stack = torch.stack(four_tensor).float()/255.0\n",
        "five_stack = torch.stack(five_tensor).float()/255.0\n",
        "six_stack = torch.stack(six_tensor).float()/255.0\n",
        "seven_stack = torch.stack(seven_tensor).float()/255.0\n",
        "eight_stack = torch.stack(eight_tensor).float()/255.0\n",
        "nine_stack = torch.stack(nine_tensor).float()/255.0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1VDufAq0c37"
      },
      "source": [
        "zero_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/0').ls().sorted()]).float()/255.0\n",
        "one_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/1').ls().sorted()]).float()/255.0\n",
        "two_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/2').ls().sorted()]).float()/255.0\n",
        "three_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/3').ls().sorted()]).float()/255.0\n",
        "four_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/4').ls().sorted()]).float()/255.0\n",
        "five_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/5').ls().sorted()]).float()/255.0\n",
        "six_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/6').ls().sorted()]).float()/255.0\n",
        "seven_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/7').ls().sorted()]).float()/255.0\n",
        "eight_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/8').ls().sorted()]).float()/255.0\n",
        "nine_t_tensor = torch.stack([tensor(Image.open(o)) for o in (path/'testing/9').ls().sorted()]).float()/255.0\n",
        "\n",
        "t_tensors = [zero_t_tensor, one_t_tensor, two_t_tensor, three_t_tensor, four_t_tensor, \n",
        "            five_t_tensor, six_t_tensor, seven_t_tensor, eight_t_tensor, nine_t_tensor]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMRpanjnPtB6"
      },
      "source": [
        "## Stochastic Gradient Descent\n",
        "\n",
        "Stochastic Gradient Descent (SGD) is a method to optimize objective function with suitable smoothness properties iteratively. The difference between SGD and gradient descent is that SGD uses mini-batch instead of processing all inputs at once, which makes SGD faster and cost efficient.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD4X_ylbSmFg"
      },
      "source": [
        "There are seven steps when trying to identify number using SGD:\n",
        "\n",
        "1. Initialize weight with random value\n",
        "1. Predict the number\n",
        "1. Calculate the model loss (how far the prediction from actual result)\n",
        "1. Calculate gradient, to measure new weight\n",
        "1. Step(change) all the weight based on calculation\n",
        "1. Go back to step 2, and repeat\n",
        "1. Iterate until you decide to stop "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "kp4oZuBUWbxD",
        "outputId": "81966ec7-4ce7-489d-85f5-c96983867f62"
      },
      "source": [
        "gv('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f8713937790>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"597pt\" height=\"78pt\"\n viewBox=\"0.00 0.00 596.69 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-74 592.6863,-74 592.6863,4 -4,4\"/>\n<!-- init -->\n<g id=\"node1\" class=\"node\">\n<title>init</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">init</text>\n</g>\n<!-- predict -->\n<g id=\"node2\" class=\"node\">\n<title>predict</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127.3968\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"127.3968\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n</g>\n<!-- init&#45;&gt;predict -->\n<g id=\"edge1\" class=\"edge\">\n<title>init&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1688,-18C62.3543,-18 71.5827,-18 80.6596,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7795,-21.5001 90.7795,-18 80.7795,-14.5001 80.7795,-21.5001\"/>\n</g>\n<!-- loss -->\n<g id=\"node3\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.7935\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"227.7935\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- predict&#45;&gt;loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>predict&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5191,-28.2011C168.9806,-32.0826 182.1139,-36.5303 193.9014,-40.5222\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.8259,-43.8532 203.4202,-43.7458 195.0713,-37.2231 192.8259,-43.8532\"/>\n</g>\n<!-- gradient -->\n<g id=\"node4\" class=\"node\">\n<title>gradient</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.7399\" cy=\"-52\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"365.7399\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gradient</text>\n</g>\n<!-- loss&#45;&gt;gradient -->\n<g id=\"edge3\" class=\"edge\">\n<title>loss&#45;&gt;gradient</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.0473,-52C272.0415,-52 294.4481,-52 314.6545,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.671,-55.5001 324.671,-52 314.671,-48.5001 314.671,-55.5001\"/>\n</g>\n<!-- step -->\n<g id=\"node5\" class=\"node\">\n<title>step</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"470.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"470.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step</text>\n</g>\n<!-- gradient&#45;&gt;step -->\n<g id=\"edge4\" class=\"edge\">\n<title>gradient&#45;&gt;step</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M398.9456,-41.2422C410.9558,-37.3512 424.5297,-32.9536 436.6132,-29.0388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.9112,-32.2975 446.3457,-25.8857 435.7537,-25.6382 437.9112,-32.2975\"/>\n</g>\n<!-- step&#45;&gt;predict -->\n<g id=\"edge6\" class=\"edge\">\n<title>step&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.4266,-18C384.9297,-18 246.7861,-18 174.0495,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.8098,-14.5001 163.8098,-18 173.8097,-21.5001 173.8098,-14.5001\"/>\n<text text-anchor=\"middle\" x=\"289.7935\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n</g>\n<!-- stop -->\n<g id=\"node6\" class=\"node\">\n<title>stop</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"561.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"561.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n</g>\n<!-- step&#45;&gt;stop -->\n<g id=\"edge5\" class=\"edge\">\n<title>step&#45;&gt;stop</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M497.9893,-18C506.2676,-18 515.508,-18 524.3268,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.4026,-21.5001 534.4025,-18 524.4025,-14.5001 524.4026,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BuIIpr-bnP4"
      },
      "source": [
        "### Mini-Batch\n",
        "To split data into several batches, I use `DataLoader` class to load data, randomize the entry, and split the data into several batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI8MqZz5cWio"
      },
      "source": [
        "train_x = torch.cat([zero_stack, one_stack,  two_stack, three_stack, four_stack, five_stack, six_stack, seven_stack, eight_stack, nine_stack]).view(-1, 28*28)\n",
        "train_y = tensor([0]* len(zeros) + [1]* len(ones) + [2]* len(twos) + [3]* len(threes) + [4]* len(fours) + [5]* len(fives) + \n",
        "                 [6]* len(sixes) + [7]* len(sevens) + [8]* len(eights) + [9]* len(nines))\n",
        "train_dl = DataLoader(list(zip(train_x, train_y)), batch_size=256)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcq-Zf_Jd129"
      },
      "source": [
        "validation_x = torch.cat([zero_t_tensor, one_t_tensor, two_t_tensor, three_t_tensor, four_t_tensor, five_t_tensor, \n",
        "                     six_t_tensor, seven_t_tensor, eight_t_tensor, nine_t_tensor]).view(-1, 28*28)\n",
        "validation_y = tensor([0]* len(zero_t_tensor) + [1]* len(one_t_tensor) + [2]* len(two_t_tensor) + [3]* len(three_t_tensor) + [4]* len(four_t_tensor) + [5]* len(five_t_tensor) + \n",
        "                 [6]* len(six_t_tensor) + [7]* len(seven_t_tensor) + [8]* len(eight_t_tensor) + [9]* len(nine_t_tensor))\n",
        "validation_dl = DataLoader(list(zip(validation_x, validation_y)), batch_size=256)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfy5BzPRnnEu"
      },
      "source": [
        "In the code above, I map the X axis with image tensors, and Y axis with numbering label to create training and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sg_Evu-vSTA"
      },
      "source": [
        "def train_epoch(model):\n",
        "  result = []\n",
        "  for xb, yb in train_dl:\n",
        "    loss = calculate_gradient(xb, yb, model)\n",
        "    for p in params:\n",
        "      p.data -= p.grad * lr\n",
        "      p.grad.zero_()\n",
        "    result.append(loss.detach())\n",
        "  return torch.stack(result).mean()\n",
        "\n",
        "def calculate_gradient(xb, yb, model, loss_func=F.cross_entropy):\n",
        "  preds = model(xb)\n",
        "  loss = loss_func(preds, yb)\n",
        "  loss.backward()\n",
        "\n",
        "  return loss\n",
        "\n",
        "def train_model(model, epochs):\n",
        "    for i in range(epochs):\n",
        "        loss = train_epoch(model)\n",
        "        accuracy = validate_epoch(model)\n",
        "        print(f\"Loss: {loss}\")\n",
        "        print(f\"Accuracy: {accuracy}\")\n",
        "        \n",
        "def linear1(xb):\n",
        "    return xb@w + b\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLISkMvOQ8Uy"
      },
      "source": [
        "def validate_epoch(model):\n",
        "  accs = [batch_accuracy(model(xb), yb) for xb, yb in validation_dl]\n",
        "  return round(torch.stack(accs).mean().item(), 4)\n",
        "\n",
        "def batch_accuracy(result, yb):\n",
        "  scores = result.softmax(1)\n",
        "  accuracy = num_correct(scores, yb) / float(yb.size(0))\n",
        "  return accuracy\n",
        "\n",
        "def num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).float().sum()\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH3HckkZIGNG"
      },
      "source": [
        "I define several functions. `train_model` is the main method that will be used to view function loss and mode accuracy. In every epoch, functions `train_epoch` and `validate_epoch` is called sequentially. In `train_epoch`, the function will calculate gradient by using cross entropy.\n",
        "\n",
        "In validation process, `batch_accuracy` will caluclate SoftMax distribution. This distribution determines probability of a numeric image detection result from number 0 to 9. In `num_correct`, the function will get which array index (array index is a representation of number result) has highest probability, and will be compared with actual result to test the model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq11AOR9zLbx"
      },
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
        "\n",
        "#Init variables with random values\n",
        "w = init_params((28*28, 10))\n",
        "b = init_params(10)\n",
        "\n",
        "params = w , b\n",
        "lr = 1.\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iblC1XF3JBeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d91cb0e-cbe6-4372-ccb8-74974913056c"
      },
      "source": [
        "#Print weight and bias before training\n",
        "params"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.9269,  1.4873,  0.9007,  ..., -1.6047, -0.7521,  1.6487],\n",
              "         [-0.3925, -1.4036, -0.7279,  ..., -0.1596, -0.4974,  0.4396],\n",
              "         [-0.7581,  1.0783,  0.8008,  ...,  1.3347, -0.2316,  0.0418],\n",
              "         ...,\n",
              "         [-0.0560, -0.4547,  1.2942,  ...,  1.1133,  2.1901,  0.3531],\n",
              "         [ 0.4474,  0.7192, -1.9300,  ..., -0.8714,  0.2235,  0.2528],\n",
              "         [ 0.2169,  0.4700,  0.3268,  ...,  0.0470,  0.5487, -1.9951]], requires_grad=True),\n",
              " tensor([ 1.3673, -0.3805,  0.4782,  1.3093,  0.5289,  1.6473,  1.4642,  0.2509,  0.9407,  0.8538], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrBsW-Q47uU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172bc951-a3f3-4358-b9e4-860d829723f9"
      },
      "source": [
        "validate_epoch(linear1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVb7z0T9ynRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16ad91a-5382-4ea7-a593-b829a69d435c"
      },
      "source": [
        "train_model(linear1, 20)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 1.136893391609192\n",
            "Accuracy: 0.2582\n",
            "Loss: 0.5502617359161377\n",
            "Accuracy: 0.2812\n",
            "Loss: 0.39715373516082764\n",
            "Accuracy: 0.3349\n",
            "Loss: 0.3519817888736725\n",
            "Accuracy: 0.3755\n",
            "Loss: 0.3236941397190094\n",
            "Accuracy: 0.4091\n",
            "Loss: 0.305554062128067\n",
            "Accuracy: 0.4286\n",
            "Loss: 0.29184842109680176\n",
            "Accuracy: 0.4418\n",
            "Loss: 0.27974575757980347\n",
            "Accuracy: 0.4519\n",
            "Loss: 0.2693098783493042\n",
            "Accuracy: 0.4601\n",
            "Loss: 0.2599692642688751\n",
            "Accuracy: 0.4683\n",
            "Loss: 0.251607209444046\n",
            "Accuracy: 0.4736\n",
            "Loss: 0.2442314773797989\n",
            "Accuracy: 0.4811\n",
            "Loss: 0.23770566284656525\n",
            "Accuracy: 0.4863\n",
            "Loss: 0.2319006621837616\n",
            "Accuracy: 0.4907\n",
            "Loss: 0.22666725516319275\n",
            "Accuracy: 0.495\n",
            "Loss: 0.22190703451633453\n",
            "Accuracy: 0.4981\n",
            "Loss: 0.2175596058368683\n",
            "Accuracy: 0.5015\n",
            "Loss: 0.21358345448970795\n",
            "Accuracy: 0.504\n",
            "Loss: 0.20994223654270172\n",
            "Accuracy: 0.5066\n",
            "Loss: 0.2065952718257904\n",
            "Accuracy: 0.5094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT_X-dJAI-T1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3580bb-f068-4565-bf54-82e3f1eb10ed"
      },
      "source": [
        "# Print weight and bias after training\n",
        "params"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.9269,  1.4873,  0.9007,  ..., -1.6047, -0.7521,  1.6487],\n",
              "         [-0.3925, -1.4036, -0.7279,  ..., -0.1596, -0.4974,  0.4396],\n",
              "         [-0.7581,  1.0783,  0.8008,  ...,  1.3347, -0.2316,  0.0418],\n",
              "         ...,\n",
              "         [-0.0560, -0.4547,  1.2942,  ...,  1.1133,  2.1901,  0.3531],\n",
              "         [ 0.4474,  0.7192, -1.9300,  ..., -0.8714,  0.2235,  0.2528],\n",
              "         [ 0.2169,  0.4700,  0.3268,  ...,  0.0470,  0.5487, -1.9951]], requires_grad=True),\n",
              " tensor([-0.5247,  0.7532,  1.2962, -0.8335,  0.3063,  5.2543,  0.7062,  2.5766, -2.2327,  1.1580], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}